{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ded430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import sys # Python system library needed to load custom functions\n",
    "import math # module with access to mathematical functions\n",
    "import os # for changing the directory\n",
    "\n",
    "import numpy as np  # for performing calculations on numerical arrays\n",
    "import pandas as pd  # home of the DataFrame construct, _the_ most important object for Data Science\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  # allows creation of insightful plots\n",
    "\n",
    "sys.path.append('../../audio_preprocessing')\n",
    "sys.path.append('../../src')\n",
    "sys.path.append('../../model_training_utils')\n",
    "\n",
    "\n",
    "import preprocessing_func_3\n",
    "from generator_to_dataset_3 import NormalisedDataSet\n",
    "from gdsc_utils import PROJECT_DIR\n",
    "import model_training\n",
    "import model_eval\n",
    "\n",
    "os.chdir(PROJECT_DIR) # changing our directory to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91305c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89379</th>\n",
       "      <td>65625</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65625.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89380</th>\n",
       "      <td>65626</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65626.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89381</th>\n",
       "      <td>65627</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65627.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89382</th>\n",
       "      <td>65628</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65628.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89383</th>\n",
       "      <td>65629</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65629.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       file_path  label\n",
       "89379       65625  data/big_data_upsample_train_and_val/65625.wav     65\n",
       "89380       65626  data/big_data_upsample_train_and_val/65626.wav     65\n",
       "89381       65627  data/big_data_upsample_train_and_val/65627.wav     65\n",
       "89382       65628  data/big_data_upsample_train_and_val/65628.wav     65\n",
       "89383       65629  data/big_data_upsample_train_and_val/65629.wav     65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_data = pd.read_csv('data/big_data_processed_train_and_val.csv')\n",
    "df_big_argumented_data = pd.read_csv('data/big_argumentation_data_train_and_val.csv')\n",
    "df = pd.concat([df_big_data, df_big_argumented_data], ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4f3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('audio_preprocessing/saved_data/upsampled_data_size_128_512_train_and_val.json') as f:\n",
    "    my_info = json.load(f)\n",
    "\n",
    "mean, std, class_weights = my_info[\"mean\"], my_info[\"std\"], my_info[\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a08d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1210904121398926, 0.7912123203277588)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca11a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = []\n",
    "val_df_list = []\n",
    "\n",
    "for i in range(66):\n",
    "    my_df = df[df[\"label\"] == i]\n",
    "    current_train_df, current_val_df = train_test_split(my_df, test_size=0.01)\n",
    "    train_df_list.append(current_train_df)\n",
    "    val_df_list.append(current_val_df)\n",
    "\n",
    "df_train = pd.concat(train_df_list, ignore_index=True)\n",
    "df_val = pd.concat(val_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9cce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88458, 3), (926, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a2eb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_train, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_val, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=28)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "694fbc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = model_training.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56e960a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_s\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "#resnet_model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "efficientnet_v2_s_model = efficientnet_v2_s(num_classes=66)\n",
    "efficientnet_v2_s_model.features[0][0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "efficientnet_v2_s_model = efficientnet_v2_s_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0ed5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(efficientnet_v2_s_model.parameters(), amsgrad=True)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4225a89a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_training\u001b[38;5;241m.\u001b[39mtraining(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mefficientnet_v2_s_model, \n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m      4\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mloss, \n\u001b[0;32m      5\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, \n\u001b[0;32m      6\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader, \n\u001b[0;32m      7\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/EfficientNetV2_train_and_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      8\u001b[0m     start_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m     10\u001b[0m     early_stop_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\AnacondaProjects\\insects_classification\\model_definition_and_training\\EfficientNetV2\\../../model_training_utils\\model_training.py:66\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, optimizer, loss_fn, train_dataloader, val_dataloader, model_path, epochs, early_stop_thresh, lr_decay, device, start_epoch)\u001b[0m\n\u001b[0;32m     63\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     65\u001b[0m     train_batch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 66\u001b[0m     train_labels\u001b[38;5;241m.\u001b[39mappend(y_batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     67\u001b[0m     train_predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \n\u001b[0;32m     69\u001b[0m training_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_training.training(\n",
    "    model=efficientnet_v2_s_model, \n",
    "    optimizer=optimizer, \n",
    "    loss_fn=loss, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=val_dataloader, \n",
    "    model_path=\"models/EfficientNetV2_train_and_val\", \n",
    "    start_epoch=13,\n",
    "    epochs=500,\n",
    "    early_stop_thresh=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f30270",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_v2_s_model, 'models/EfficientNetV2_train_and_val/efficientnet_model_epoch_13.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
