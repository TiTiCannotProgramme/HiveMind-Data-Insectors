{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d262fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import sys # Python system library needed to load custom functions\n",
    "import math # module with access to mathematical functions\n",
    "import os # for changing the directory\n",
    "\n",
    "import numpy as np  # for performing calculations on numerical arrays\n",
    "import pandas as pd  # home of the DataFrame construct, _the_ most important object for Data Science\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  # allows creation of insightful plots\n",
    "\n",
    "sys.path.append('../../audio_preprocessing')\n",
    "sys.path.append('../../src')\n",
    "sys.path.append('../../model_training_utils')\n",
    "\n",
    "\n",
    "import preprocessing_func_3\n",
    "from generator_to_dataset_3 import NormalisedDataSet\n",
    "from gdsc_utils import PROJECT_DIR\n",
    "import model_training\n",
    "import model_eval\n",
    "\n",
    "os.chdir(PROJECT_DIR) # changing our directory to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e91b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66835</th>\n",
       "      <td>44959</td>\n",
       "      <td>data/big_data_upsample/44959.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66836</th>\n",
       "      <td>44960</td>\n",
       "      <td>data/big_data_upsample/44960.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66837</th>\n",
       "      <td>44961</td>\n",
       "      <td>data/big_data_upsample/44961.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66838</th>\n",
       "      <td>44962</td>\n",
       "      <td>data/big_data_upsample/44962.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66839</th>\n",
       "      <td>44963</td>\n",
       "      <td>data/big_data_upsample/44963.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                         file_path  label\n",
       "66835       44959  data/big_data_upsample/44959.wav     65\n",
       "66836       44960  data/big_data_upsample/44960.wav     65\n",
       "66837       44961  data/big_data_upsample/44961.wav     65\n",
       "66838       44962  data/big_data_upsample/44962.wav     65\n",
       "66839       44963  data/big_data_upsample/44963.wav     65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_data = pd.read_csv('data/big_processed_data.csv')\n",
    "df_big_argumented_data = pd.read_csv('data/big_argumentation_data.csv')\n",
    "df = pd.concat([df_big_data, df_big_argumented_data], ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a72167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('audio_preprocessing/saved_data/upsampled_data_size_128_512.json') as f:\n",
    "    my_info = json.load(f)\n",
    "\n",
    "mean, std, class_weights = my_info[\"mean\"], my_info[\"std\"], my_info[\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8298565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = []\n",
    "val_df_list = []\n",
    "\n",
    "for i in range(66):\n",
    "    my_df = df[df[\"label\"] == i]\n",
    "    current_train_df, current_val_df = train_test_split(my_df, test_size=0.2)\n",
    "    train_df_list.append(current_train_df)\n",
    "    val_df_list.append(current_val_df)\n",
    "\n",
    "df_train = pd.concat(train_df_list, ignore_index=True)\n",
    "df_val = pd.concat(val_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfecb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53441, 3), (13399, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f4d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_train, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_val, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=28)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1451ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = model_training.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0e2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_v2_s\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "#resnet_model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "efficientnet_v2_s_model = efficientnet_v2_s(num_classes=66)\n",
    "efficientnet_v2_s_model.features[0][0] = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "efficientnet_v2_s_model = efficientnet_v2_s_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640637a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(efficientnet_v2_s_model.parameters(), amsgrad=True)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea7106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 5: training accuracy = 97.75%, training loss = 0.07468436123597626, training time taken = 881.31 seconds\n",
      "End of epoch 5: validation accuracy = 98.56%, validation loss = 0.045008501832766314, validation time taken = 300.58 seconds\n",
      "End of epoch 6: training accuracy = 98.16%, training loss = 0.06048193436551608, training time taken = 1618.39 seconds\n",
      "End of epoch 6: validation accuracy = 98.96%, validation loss = 0.03279907385617026, validation time taken = 284.90 seconds\n",
      "End of epoch 7: training accuracy = 98.60%, training loss = 0.04486010109755495, training time taken = 1456.32 seconds\n",
      "End of epoch 7: validation accuracy = 98.22%, validation loss = 0.05949891274853529, validation time taken = 246.57 seconds\n",
      "End of epoch 8: training accuracy = 98.71%, training loss = 0.04237468255008827, training time taken = 1494.08 seconds\n",
      "End of epoch 8: validation accuracy = 99.10%, validation loss = 0.030668059088461225, validation time taken = 254.65 seconds\n",
      "End of epoch 9: training accuracy = 99.00%, training loss = 0.032718915936369754, training time taken = 1558.41 seconds\n",
      "End of epoch 9: validation accuracy = 99.02%, validation loss = 0.03062155320224638, validation time taken = 271.98 seconds\n",
      "End of epoch 10: training accuracy = 99.15%, training loss = 0.02673468416576886, training time taken = 1512.42 seconds\n",
      "End of epoch 10: validation accuracy = 98.99%, validation loss = 0.033030562780079605, validation time taken = 249.59 seconds\n",
      "End of epoch 11: training accuracy = 99.16%, training loss = 0.027774871534441147, training time taken = 1570.21 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_training\u001b[38;5;241m.\u001b[39mtraining(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mefficientnet_v2_s_model, \n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m      4\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mloss, \n\u001b[0;32m      5\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, \n\u001b[0;32m      6\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader, \n\u001b[0;32m      7\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/EfficientNetV2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      8\u001b[0m     start_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m     10\u001b[0m     early_stop_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\AnacondaProjects\\insects_classification\\model_definition_and_training\\EfficientNetV2\\../../model_training_utils\\model_training.py:95\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, optimizer, loss_fn, train_dataloader, val_dataloader, model_path, epochs, early_stop_thresh, lr_decay, device, start_epoch)\u001b[0m\n\u001b[0;32m     92\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n\u001b[0;32m     94\u001b[0m     val_batch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 95\u001b[0m     val_labels\u001b[38;5;241m.\u001b[39mappend(y_batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     96\u001b[0m     val_predictions\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))  \n\u001b[0;32m     98\u001b[0m val_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_training.training(\n",
    "    model=efficientnet_v2_s_model, \n",
    "    optimizer=optimizer, \n",
    "    loss_fn=loss, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=val_dataloader, \n",
    "    model_path=\"models/EfficientNetV2\", \n",
    "    start_epoch=4,\n",
    "    epochs=500,\n",
    "    early_stop_thresh=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f22b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_v2_s_model, 'models/EfficientNetV2/efficientnet_v2_s_model_epoch_10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a90984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing_func_2\n",
    "\n",
    "df_big_long_wav = pd.read_csv('data/metadata.csv')\n",
    "df_val_long_wav = df_big_long_wav[df_big_long_wav[\"subset\"]==\"validation\"]\n",
    "\n",
    "def get_df_from_class(class_num, df):\n",
    "    new_df = df[df[\"label\"] == class_num]\n",
    "    return new_df\n",
    "\n",
    "for i in range(66):\n",
    "    df_val_new = get_df_from_class(i, df_val_long_wav)\n",
    "    paths, labels = list(df_val_new[\"path\"]), list(df_val_new[\"label\"])\n",
    "    non_normalised_generator = preprocessing_func_2.non_normalised_data_generator(paths, labels)\n",
    "    normalised_generator = preprocessing_func_2.normalised_data_generator(\n",
    "        non_normalised_generator, mean, std)\n",
    "    print(f\"we are now in class {i}\")\n",
    "    final_pred = model_eval.evaluation(efficientnet_v2_s_model, normalised_generator)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df314b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big_long_wav = pd.read_csv('data/metadata.csv')\n",
    "df_val_long_wav = df_big_long_wav[df_big_long_wav[\"subset\"]==\"validation\"]\n",
    "\n",
    "\n",
    "paths, labels = list(df_val_long_wav[\"path\"]), list(df_val_long_wav[\"label\"])\n",
    "non_normalised_generator = preprocessing_func_2.non_normalised_data_generator(paths, labels)\n",
    "normalised_generator = preprocessing_func_2.normalised_data_generator(non_normalised_generator, mean, std)\n",
    "model_eval.evaluation(efficientnet_v2_s_model, normalised_generator, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a04c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
