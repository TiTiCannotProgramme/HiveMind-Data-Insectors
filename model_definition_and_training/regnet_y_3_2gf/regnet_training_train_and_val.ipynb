{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da019f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import sys # Python system library needed to load custom functions\n",
    "import math # module with access to mathematical functions\n",
    "import os # for changing the directory\n",
    "\n",
    "import numpy as np  # for performing calculations on numerical arrays\n",
    "import pandas as pd  # home of the DataFrame construct, _the_ most important object for Data Science\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt  # allows creation of insightful plots\n",
    "\n",
    "sys.path.append('../../audio_preprocessing')\n",
    "sys.path.append('../../src')\n",
    "sys.path.append('../../model_training_utils')\n",
    "\n",
    "\n",
    "import preprocessing_func_3\n",
    "from generator_to_dataset_3 import NormalisedDataSet\n",
    "from gdsc_utils import PROJECT_DIR\n",
    "import model_training\n",
    "import model_eval\n",
    "\n",
    "os.chdir(PROJECT_DIR) # changing our directory to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4278ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89379</th>\n",
       "      <td>65625</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65625.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89380</th>\n",
       "      <td>65626</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65626.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89381</th>\n",
       "      <td>65627</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65627.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89382</th>\n",
       "      <td>65628</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65628.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89383</th>\n",
       "      <td>65629</td>\n",
       "      <td>data/big_data_upsample_train_and_val/65629.wav</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       file_path  label\n",
       "89379       65625  data/big_data_upsample_train_and_val/65625.wav     65\n",
       "89380       65626  data/big_data_upsample_train_and_val/65626.wav     65\n",
       "89381       65627  data/big_data_upsample_train_and_val/65627.wav     65\n",
       "89382       65628  data/big_data_upsample_train_and_val/65628.wav     65\n",
       "89383       65629  data/big_data_upsample_train_and_val/65629.wav     65"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_big_data = pd.read_csv('data/big_data_processed_train_and_val.csv')\n",
    "df_big_argumented_data = pd.read_csv('data/big_argumentation_data_train_and_val.csv')\n",
    "df = pd.concat([df_big_data, df_big_argumented_data], ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7def670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('audio_preprocessing/saved_data/upsampled_data_size_128_512_train_and_val.json') as f:\n",
    "    my_info = json.load(f)\n",
    "\n",
    "mean, std, class_weights = my_info[\"mean\"], my_info[\"std\"], my_info[\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222d9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = []\n",
    "val_df_list = []\n",
    "\n",
    "for i in range(66):\n",
    "    my_df = df[df[\"label\"] == i]\n",
    "    current_train_df, current_val_df = train_test_split(my_df, test_size=0.2)\n",
    "    train_df_list.append(current_train_df)\n",
    "    val_df_list.append(current_val_df)\n",
    "\n",
    "df_train = pd.concat(train_df_list, ignore_index=True)\n",
    "df_val = pd.concat(val_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1878a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71481, 3), (17903, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eba68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths, labels = list(df_train[\"file_path\"]), list(df_train[\"label\"])\n",
    "\n",
    "# non_normal_gen = preprocessing_func_3.non_normalised_data_generator(\n",
    "#     paths=paths,\n",
    "#     labels=labels,\n",
    "# #     image_preprocess_fn=resize_function(output_shape=(40,256)),\n",
    "# #     mel_transform_fn=calculate_melsp\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ed09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std, class_wights = preprocessing_func_3.get_stats_and_class_weights_of_non_normalised_data_gen(\n",
    "#     non_normal_gen, (128, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fc1c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1210904121398926, 0.7912123203277588)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d8e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# def save_as_json(path, description, mean, std, weights):\n",
    "#     my_dict = {\n",
    "#         \"description\": description,\n",
    "#         \"mean\": float(mean),\n",
    "#         \"std\": float(std),\n",
    "#         \"weights\": list(class_wights.astype(float)),\n",
    "#     }\n",
    "#     with open(path, 'w') as f:\n",
    "#         json.dump(my_dict, f)\n",
    "\n",
    "# save_as_json(\n",
    "#     \"audio_preprocessing/saved_data/upsampled_data_size_128_512_train_and_val.json\", \n",
    "#     \"seconds 1.5, image shape (128,512)\", mean, std, class_wights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f48f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_train, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = NormalisedDataSet(\n",
    "    non_normalised_data_generator_fn=preprocessing_func_3.non_normalised_data_generator, \n",
    "    normalised_data_generator_fn=preprocessing_func_3.normalised_data_generator,\n",
    "    df=df_val, \n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=28)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b870bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = model_training.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7138ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import regnet_y_3_2gf\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "#resnet_model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "regnet_model = regnet_y_3_2gf(num_classes=66)\n",
    "regnet_model.stem[0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "regnet_model = regnet_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d21068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegNet(\n",
      "  (stem): SimpleStemIN(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (trunk_output): Sequential(\n",
      "    (block1): AnyStage(\n",
      "      (block1-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(8, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block1-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(18, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block2): AnyStage(\n",
      "      (block2-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 216, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9, bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(216, 18, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(18, 216, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-2): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-3): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block2-4): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block3): AnyStage(\n",
      "      (block3-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(216, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(216, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 54, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(54, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-1): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-2): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-3): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-4): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-5): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-6): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-7): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-8): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-9): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-10): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-11): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (block3-12): ResBottleneckBlock(\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (block4): AnyStage(\n",
      "      (block4-0): ResBottleneckBlock(\n",
      "        (proj): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 1512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (f): BottleneckTransform(\n",
      "          (a): Conv2dNormActivation(\n",
      "            (0): Conv2d(576, 1512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (b): Conv2dNormActivation(\n",
      "            (0): Conv2d(1512, 1512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=63, bias=False)\n",
      "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (se): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(1512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(144, 1512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Sigmoid()\n",
      "          )\n",
      "          (c): Conv2dNormActivation(\n",
      "            (0): Conv2d(1512, 1512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=1512, out_features=66, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(regnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aaa2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(regnet_model.parameters(), amsgrad=True)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed6dd71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_training\u001b[38;5;241m.\u001b[39mtraining(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mregnet_model, \n\u001b[0;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer, \n\u001b[0;32m      4\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39mloss, \n\u001b[0;32m      5\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, \n\u001b[0;32m      6\u001b[0m     val_dataloader\u001b[38;5;241m=\u001b[39mval_dataloader, \n\u001b[0;32m      7\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/regnet_y_3_2gf_train_and_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      8\u001b[0m     start_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m,\n\u001b[0;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[0;32m     10\u001b[0m     early_stop_thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\AnacondaProjects\\insects_classification\\model_definition_and_training\\regnet_y_3_2gf\\../../model_training_utils\\model_training.py:63\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(model, optimizer, loss_fn, train_dataloader, val_dataloader, model_path, epochs, early_stop_thresh, lr_decay, device, start_epoch)\u001b[0m\n\u001b[0;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     62\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     65\u001b[0m train_batch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     66\u001b[0m train_labels\u001b[38;5;241m.\u001b[39mappend(y_batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    133\u001b[0m         group,\n\u001b[0;32m    134\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    139\u001b[0m         state_steps)\n\u001b[1;32m--> 141\u001b[0m     adam(\n\u001b[0;32m    142\u001b[0m         params_with_grad,\n\u001b[0;32m    143\u001b[0m         grads,\n\u001b[0;32m    144\u001b[0m         exp_avgs,\n\u001b[0;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    147\u001b[0m         state_steps,\n\u001b[0;32m    148\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    149\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    150\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    151\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    152\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    153\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    154\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    155\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    156\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    157\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    158\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    159\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    160\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 281\u001b[0m func(params,\n\u001b[0;32m    282\u001b[0m      grads,\n\u001b[0;32m    283\u001b[0m      exp_avgs,\n\u001b[0;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    286\u001b[0m      state_steps,\n\u001b[0;32m    287\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    288\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    289\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    290\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    291\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    292\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    293\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    294\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    295\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    296\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    297\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\optim\\adam.py:446\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    445\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avgs, beta1)\n\u001b[1;32m--> 446\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_exp_avgs, device_grads, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m    448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_mul_(device_exp_avg_sqs, beta2)\n\u001b[0;32m    449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_training.training(\n",
    "    model=regnet_model, \n",
    "    optimizer=optimizer, \n",
    "    loss_fn=loss, \n",
    "    train_dataloader=train_dataloader, \n",
    "    val_dataloader=val_dataloader, \n",
    "    model_path=\"models/regnet_y_3_2gf_train_and_val\", \n",
    "    start_epoch=11,\n",
    "    epochs=500,\n",
    "    early_stop_thresh=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e59268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(regnet_model, 'models/regnet_y_3_2gf_train_and_val/regnet_model_epoch_11.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3dfb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754184c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462271ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff6a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
